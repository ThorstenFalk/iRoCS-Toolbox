/**************************************************************************
**       Title: two class NU-SVM
**    $RCSfile$
**   $Revision: 509 $$Name$
**       $Date: 2004-09-03 13:35:04 +0200 (Fri, 03 Sep 2004) $
**   Copyright: GPL $Author: ronneber $
** Description:
**
**
**
**-------------------------------------------------------------------------
**
**  $Log$
**  Revision 1.3  2004/09/03 11:35:04  ronneber
**  - replaced Chi-Jen Lin's own min,max,swap with std::min,
**    std::max. std::swap to compile with programs, that "#include
**    <algorithm>" and do a "using namespace std;"
**
**  Revision 1.2  2004/09/01 14:43:36  ronneber
**  changed IterToPointerTraits stuff to
**  DirectAccessor and DereferencingAccessor, to make code more
**  intuitive understandable
**
**  Revision 1.1  2004/08/26 08:36:59  ronneber
**  initital import
**
**  Revision 1.9  2003/05/19 11:33:13  ronneber
**  - adapted to new separate SolutionInfo class
**  - now counts additionally bounded support vectors
**  - WARNING: class is still broken (see test/testTwoClassSVM).
**    DON'T USE UNTIL THIS IS FIXED!
**
**  Revision 1.8  2003/02/10 07:36:21  ronneber
**  - adapted to g++-3.2 (iterators are not pointers)
**
**  Revision 1.7  2002/10/28 16:00:52  mechnich
**  fixed compatibility problems with gcc3
**
**  Revision 1.6  2002/06/07 12:23:32  ronneber
**  - clean up of source code
**
**  - made ModelType in train() an own template parameter to make
**    it more flexible (e.g. when using a slightly different but
**    compatible Feature Vector class)
**
**  - added two additional interfaces for train() method
**
**  - moved functionality of train_one() and solve_nu_svc() method
**    into low-level train() method
**
**  Revision 1.5  2002/06/05 17:18:31  mechnich
**  Made minor corrections for compilation under Win32
**
**  Revision 1.4  2002/05/13 16:28:50  ronneber
**  - removed coutPlus and countMinus -- they could  easily be calculated
**    later by the library-user
**  - adapted to new Model and SupportVector class (without public attributes)
**
**  Revision 1.3  2002/05/10 11:07:03  ronneber
**  - removed FV template for all public classes, because Feature Vector type
**    can be extracted automatically from passed iterators or other
**    parameters -- this makes the public interface much more intuitive
**
**  Revision 1.2  2002/05/06 13:43:58  ronneber
**  - removed Parameters struct
**  - added default value for _bu according to original libsvm
**  - feature_vector-list passed from train() to train_one() has now
**    correct size, even if there are feature vectors with label 0
**  - removed some debugging output
**
**  Revision 1.1  2002/03/26 12:44:02  ronneber
**  restructured for autoconf
**
**  Revision 1.1  2002/03/13 14:10:23  pigorsch
**  * initial revision
**
**
**
**************************************************************************/

/*-------------------------------------------------------------------------
 *  default values for nu-SVM (same as original libsvm)
 *-------------------------------------------------------------------------*/
static const double NU_DEFAULT = 0.5;


template< typename KF>
svt::TwoClassSVMnu<KF>::TwoClassSVMnu()
        :TwoClassSVM<KF>(),
         _nu( NU_DEFAULT)
{}

template< typename KF>
svt::TwoClassSVMnu<KF>::TwoClassSVMnu(const KF& kernel)
        :TwoClassSVM<KF>(kernel),
         _nu( NU_DEFAULT)
{}

template< typename KF>
svt::TwoClassSVMnu<KF>::~TwoClassSVMnu()
{}



/*=========================================================================
 *  DESCRIPTION OF FUNCTION:  train (raw interface)
 *  ==> see headerfile
 *=======================================================================*/
template< typename KF>
template< typename FV>
void svt::TwoClassSVMnu<KF>::train( 
    const SVM_Problem<FV>& problem,
    Model<FV>& model) const
{
  CHECK_MEMBER_TEMPLATE_2PARAM( svt_check::RequireKernel_k_function<KF,FV>);

  const SVM_Problem<FV>* prob = &problem;  // alias for compatibility with original code
  double *alpha = new double[ prob->l];
  if( this->_pr != 0)
  {
    this->_pr->reportProgress( TASK_LEVEL_TWOCLASS, "training Two-Class SVM", -2, "");
  }
  
 	SolutionInfo si;
        solve_nu_svc( prob, alpha, &si, model);
	// info("obj = %f, rho = %f\n",si.obj,si.rho);
        model.setTrainingInfoValue( "obj", si.obj);
        
	// output SVs

	int nSV = 0;
	int nBSV = 0;
	for(int i=0;i<prob->l;i++)
	{
		if(fabs(alpha[i]) > 0)
		{
			++nSV;
			if(prob->y[i] > 0)
			{
				if(fabs(alpha[i]) >= si.upper_bound_p)
					++nBSV;
			}
			else
			{
				if(fabs(alpha[i]) >= si.upper_bound_n)
					++nBSV;
			}
		}
	}

	// info("nSV = %d, nBSV = %d\n",nSV,nBSV);

  model.setTrainingInfoValue( "nSV", nSV);
  model.setTrainingInfoValue( "nBSV", nBSV);
  model.setTrainingInfoValue( "nu", _nu);
  model.setTrainingInfoValue( "iterations", si.iter);
  model.setTrainingInfoValue( "upper_bound_p", si.upper_bound_p);
  model.setTrainingInfoValue( "upper_bound_n", si.upper_bound_n);
  
  // to simplify statistics, we also store number of training vectors
  model.setTrainingInfoValue( "nFV", prob->l);

  // copy support vectors into model
  model.resize( nSV);
  int modelIndex = 0;
  for( int i = 0; i < prob->l; ++i)
  {
    if( fabs(alpha[i]) > 0)
    {
      model.allSupportVectors()[modelIndex] = prob->x[i];
      model.allAlphas()[modelIndex] = alpha[i];
      ++modelIndex;
    }
  }
  
  model.setRho( si.rho);
  /*-----------------------------------------------------------------------
   *  free alphas
   *-----------------------------------------------------------------------*/
  delete[] alpha;

}

/*=========================================================================
 *  DESCRIPTION OF FUNCTION: train() STL-like interface with accessor
 *  ==> see headerfile
 *=======================================================================*/
template< typename KF>
template< typename ForwardIter, typename Accessor>
void svt::TwoClassSVMnu<KF>::train( 
    ForwardIter FV_begin, const ForwardIter& FV_end,
    svt::Model<typename Accessor::template Traits<ForwardIter>::value_type>& model,
    Accessor accessor) const
{
  typedef typename Accessor::template Traits<ForwardIter>::value_type FV;

  CHECK_MEMBER_TEMPLATE( svt_check::RequireForwardIter<ForwardIter>);
  CHECK_MEMBER_TEMPLATE_2PARAM( svt_check::RequireKernel_k_function<KF,FV>);

  /*-----------------------------------------------------------------------
   *  Create SVM_Problem from given feature vectors
   *-----------------------------------------------------------------------*/
  int size = FV_end - FV_begin;
  svt::SVM_Problem<FV> prob( size);
  ForwardIter itF = FV_begin;
  for( int i = 0; i < size; ++i)
  {
    prob.x[i] = &(accessor(itF));
    prob.y[i] = accessor(itF).getLabel();
    ++itF;
  }
  
  /*-----------------------------------------------------------------------
   *  Call train() with raw interface
   *-----------------------------------------------------------------------*/
  train( prob, model);

}


template<typename KF>
template<typename FV>
void svt::TwoClassSVMnu<KF>::solve_nu_svc(
    const SVM_Problem<FV>* prob,
    double *alpha, 
    SolutionInfo* si,
    Model<FV>& model) const
{
	int i;
	int l = prob->l;
	double nu = _nu;

	schar *y = new schar[l];

	for(i=0;i<l;i++)
		if(prob->y[i]>0)
			y[i] = +1;
		else
			y[i] = -1;

	double sum_pos = nu*l/2;
	double sum_neg = nu*l/2;

	for(i=0;i<l;i++)
		if(y[i] == +1)
		{
			alpha[i] = std::min(1.0,sum_pos);
			sum_pos -= alpha[i];
		}
		else
		{
			alpha[i] = std::min(1.0,sum_neg);
			sum_neg -= alpha[i];
		}

	double *zeros = new double[l];

	for(i=0;i<l;i++)
		zeros[i] = 0;

	Solver_NU<FV,KF> s;
        SVC_Q<FV,KF> svc(this->p_kernel,*prob,this->_cacheSizeMB,y);
	s.Solve(l, svc, 
                zeros, y, alpha, 1.0, 1.0, this->_terminationEpsilon, si, 
                this->_shrinkingFlag, this->_pr);

	double r = si->r;

	// info("C = %f\n",1/r);
        model.setTrainingInfoValue( "cost", 1/r );

	for(i=0;i<l;i++)
		alpha[i] *= y[i]/r;

	si->rho /= r;
	si->obj /= (r*r);
	si->upper_bound_p = 1/r;
	si->upper_bound_n = 1/r;

	delete[] y;
	delete[] zeros;
}

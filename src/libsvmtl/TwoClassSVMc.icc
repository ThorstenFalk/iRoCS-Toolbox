/**************************************************************************
**       Title: two class C-SVM
**    $RCSfile$
**   $Revision: 4820 $$Name$
**       $Date: 2011-11-08 10:57:01 +0100 (Tue, 08 Nov 2011) $
**   Copyright: GPL $Author: tschmidt $
** Description:
**
**
**
**-------------------------------------------------------------------------
**
**  $Log$
**  Revision 1.2  2004/09/01 14:43:36  ronneber
**  changed IterToPointerTraits stuff to
**  DirectAccessor and DereferencingAccessor, to make code more
**  intuitive understandable
**
**  Revision 1.1  2004/08/26 08:36:59  ronneber
**  initital import
**
**  Revision 1.8  2003/05/19 11:29:18  ronneber
**  - adapted to new separate SolutionInfo class
**  - now counts additionally bounded support vectors
**
**  Revision 1.7  2002/10/28 16:00:52  mechnich
**  fixed compatibility problems with gcc3
**
**  Revision 1.6  2002/06/07 12:22:12  ronneber
**  - clean up of source code
**
**  - made ModelType in train() an own template parameter to make
**    it more flexible (e.g. when using a slightly different but
**    compatible Feature Vector class)
**
**  - added two additional interfaces for train() method
**
**  - moved functionality of train_one() and solve_c_svc() method
**    into low-level train() method
**
**  Revision 1.5  2002/06/05 17:18:31  mechnich
**  Made minor corrections for compilation under Win32
**
**  Revision 1.4  2002/05/13 16:28:10  ronneber
**  - removed coutPlus and countMinus -- they could  easily be calculated
**    later by the library-user
**  - adapted to new Model and SupportVector class (without public attributes)
**
**  Revision 1.3  2002/05/10 11:07:03  ronneber
**  - removed FV template for all public classes, because Feature Vector type
**    can be extracted automatically from passed iterators or other
**    parameters -- this makes the public interface much more intuitive
**
**  Revision 1.2  2002/05/06 13:40:22  ronneber
**  - removed Parameters struct
**  - added default values for _cost and _positiveClassWeight according to
**    original libsvm
**  - feature_vector-list passed from train() to train_one() has now
**    correct size, even if there are feature vectors with label 0
**  - removed some debugging output
**
**  Revision 1.1  2002/03/26 12:44:02  ronneber
**  restructured for autoconf
**
**  Revision 1.1  2002/03/13 14:08:41  pigorsch
**  * initial revision
**
**
**
**************************************************************************/



/*=========================================================================
 *  DESCRIPTION OF FUNCTION:  train (raw interface)
 *  ==> see headerfile
 *=======================================================================*/
template< typename KF>
template< typename FV>
void svt::TwoClassSVMc<KF>::train( 
    const SVM_Problem<FV>& problem,
    Model<FV>& model) const
{
  CHECK_MEMBER_TEMPLATE_2PARAM( svt_check::RequireKernel_k_function<KF,FV>);

  const SVM_Problem<FV>* prob = &problem;  // alias for compatibility with original code
  double *alpha = new double[ prob->l];
  if( this->_pr != 0)
  {
    this->_pr->reportProgress( TASK_LEVEL_TWOCLASS, "training Two-Class SVM", -2, "");
  }
  
 	SolutionInfo si;
        solve_c_svc( prob, alpha, &si, model);
	//info("obj = %f, rho = %f\n",si.obj,si.rho);
        model.setTrainingInfoValue( "obj", si.obj);
        
	// output SVs

	int nSV = 0;
	int nBSV = 0;
	for(int i=0;i<prob->l;i++)
	{
		if(fabs(alpha[i]) > 0)
		{
			++nSV;
			if(prob->y[i] > 0)
			{
				if(fabs(alpha[i]) >= si.upper_bound_p)
					++nBSV;
			}
			else
			{
				if(fabs(alpha[i]) >= si.upper_bound_n)
					++nBSV;
			}
		}
	}

	//info("nSV = %d, nBSV = %d\n",nSV,nBSV);
 model.setTrainingInfoValue( "nSV", nSV);
 model.setTrainingInfoValue( "nBSV", nBSV);
 model.setTrainingInfoValue( "cost", _cost);
 model.setTrainingInfoValue( "iterations", si.iter);
   
   // to simplify statistics, we also store number of training vectors
  model.setTrainingInfoValue( "nFV", prob->l);
  
  // copy support vectors into model
  model.resize( nSV);
  int modelIndex = 0;
  for( int i = 0; i < prob->l; ++i)
  {
    if( fabs(alpha[i]) > 0)
    {
      model.allSupportVectors()[modelIndex] = prob->x[i];
      model.allAlphas()[modelIndex] = alpha[i];
      ++modelIndex;
    }
    
  }
  

  model.setRho( si.rho);

  /*-----------------------------------------------------------------------
   *  free alphas
   *-----------------------------------------------------------------------*/
  delete[] alpha;
  
}

/*=========================================================================
 *  DESCRIPTION OF FUNCTION: train() STL-like interface with accessor
 *  ==> see headerfile
 *=======================================================================*/
template< typename KF>
template< typename ForwardIter, typename Accessor>
void svt::TwoClassSVMc<KF>::train( 
    ForwardIter FV_begin, const ForwardIter& FV_end,
    svt::Model<typename Accessor::template Traits<ForwardIter>::value_type>& model,
    Accessor accessor) const
{
  typedef typename Accessor::template Traits<ForwardIter>::value_type FV;

  CHECK_MEMBER_TEMPLATE( svt_check::RequireForwardIter<ForwardIter>);
  CHECK_MEMBER_TEMPLATE_2PARAM( svt_check::RequireKernel_k_function<KF,FV>);

  /*-----------------------------------------------------------------------
   *  Create SVM_Problem from given feature vectors
   *-----------------------------------------------------------------------*/
  size_t size = FV_end - FV_begin;
  svt::SVM_Problem<FV> prob(static_cast<int>(size));
  ForwardIter itF = FV_begin;
  for(size_t i = 0; i < size; ++i)
  {
    prob.x[i] = &(accessor(itF));
    prob.y[i] = accessor(itF).getLabel();
    ++itF;
  }
  
  /*-----------------------------------------------------------------------
   *  Call train() with raw interface
   *-----------------------------------------------------------------------*/
  train( prob, model);

}



/*=========================================================================
 *  DESCRIPTION OF FUNCTION:  solve_c_svc
 *  ==> see headerfile
 *=======================================================================*/
template<typename KF>
template<typename FV>
void svt::TwoClassSVMc<KF>::solve_c_svc(
    const SVM_Problem<FV>* prob,
    double *alpha, 
    SolutionInfo* si,
    Model<FV>& model) const
{
  double Cp = _cost * _positiveClassWeight;
  double Cn = _cost;
  

	int l = prob->l;
	double *minus_ones = new double[l];
	schar *y = new schar[l];

	int i;

	for(i=0;i<l;i++)
	{
		alpha[i] = 0;
		minus_ones[i] = -1;
		if(prob->y[i] > 0) y[i] = +1; else y[i]=-1;
	}

	Solver<FV,KF> s;
        SVC_Q<FV,KF> svc(this->p_kernel,*prob,this->_cacheSizeMB ,y);
        
	s.Solve(l, svc, 
                minus_ones, y, alpha, Cp, Cn, this->_terminationEpsilon, 
                si, this->_shrinkingFlag, this->_pr);

	double sum_alpha=0;
	for(i=0;i<l;i++)
		sum_alpha += alpha[i];

	if (Cp==Cn)
		model.setTrainingInfoValue("nu", sum_alpha/(Cp*prob->l));

	for(i=0;i<l;i++)
		alpha[i] *= y[i];

	delete[] minus_ones;
	delete[] y;
}

